"""
IRIS Voice Input - –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ —Å Vosk
–û—Ñ–ª–∞–π–Ω —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –≤—ã—Å–æ–∫–æ–π —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –∫ wake-word '–ò—Ä–∏—Å'
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ Vosk (–æ—Ñ–ª–∞–π–Ω) –∏ Google Speech Recognition (–æ–Ω–ª–∞–π–Ω)
–í–µ—Ä—Å–∏—è: 3.0.0 - –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è
"""

import threading
import time
import queue
import os
import json
import logging
import sys
from typing import Optional, Callable, List, Dict, Any, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('VoiceInput')

# –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
class RecognitionMode(Enum):
    """–†–µ–∂–∏–º—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"""
    VOSK = "vosk"           # –û—Ñ–ª–∞–π–Ω —Å Vosk
    GOOGLE = "google"       # –û–Ω–ª–∞–π–Ω —Å Google
    HYBRID = "hybrid"       # –ì–∏–±—Ä–∏–¥–Ω—ã–π (Vosk + Google)
    SIMPLE = "simple"       # –ü—Ä–æ—Å—Ç–æ–π –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤–≤–æ–¥


@dataclass
class RecognitionStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"""
    total_phrases: int = 0
    wake_detected: int = 0
    vosk_success: int = 0
    google_success: int = 0
    avg_confidence: float = 0.0
    last_recognition: str = ""
    audio_quality: float = 0.0


@dataclass
class AudioSettings:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ"""
    sample_rate: int = 16000
    chunk_size: int = 1600
    channels: int = 1
    energy_threshold: int = 3000
    pause_threshold: float = 0.5
    phrase_threshold: float = 0.3
    non_speaking_duration: float = 0.3
    dynamic_threshold: bool = True


# –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∏–º–ø–æ—Ä—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
try:
    from vosk import Model, KaldiRecognizer, SetLogLevel
    SetLogLevel(-1)  # –û—Ç–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ Vosk
    VOSK_AVAILABLE = True
    logger.info("Vosk —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
except ImportError as e:
    VOSK_AVAILABLE = False
    logger.warning(f"Vosk –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install vosk")

try:
    import speech_recognition as sr
    SR_AVAILABLE = True
    logger.info("SpeechRecognition —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
except ImportError as e:
    SR_AVAILABLE = False
    logger.warning(f"SpeechRecognition –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install SpeechRecognition")

try:
    import numpy as np
    import sounddevice as sd
    SOUNDDEVICE_AVAILABLE = True
    logger.info("SoundDevice –∏ NumPy —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
except ImportError as e:
    SOUNDDEVICE_AVAILABLE = False
    logger.warning(f"SoundDevice/NumPy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã: {e}. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install sounddevice numpy")

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
    logger.info("PyAudio —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
except ImportError as e:
    PYAUDIO_AVAILABLE = False
    logger.warning(f"PyAudio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pyaudio")


class VoiceInput:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–æ–¥—É–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
    - Vosk (–æ—Ñ–ª–∞–π–Ω, –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫)
    - Google Speech Recognition (–æ–Ω–ª–∞–π–Ω, –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)
    - –ì–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ)
    - –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ wake word –¥–µ—Ç–µ–∫—Ü–∏–∏
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
    """
    
    # –í–∞—Ä–∏–∞–Ω—Ç—ã wake word –¥–ª—è fuzzy matching
    WAKE_WORD_VARIANTS = [
        '–∏—Ä–∏—Å', 'iris', '–∏—Ä–∏', '–∏—Ä–∏—Å–∫–∞', '–∏—Ä–∏—Å—Å', '–∏—Ä–∏—Å–∞',
        '–∞–π—Ä–∏—Å', '–∞—Ä–∏—Å', '–∏—Ä–∏—à', '–∏—Ä–∏—Å—å', '—Ä–∏—Å', '—ç—Ä–∏—Å',
        '–∏—Ä–∏—Å—é', '–∏—Ä–∏—Å—è', '–∏—Ä–∏—Å—É', '–∏—Ä–∏—Å–µ'
    ]
    
    # –ë—ã—Å—Ç—Ä—ã–µ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    QUICK_COMMANDS = {
        '—Å—Ç–æ–ø': 'stop', '–æ—Å—Ç–∞–Ω–æ–≤–∏—Å—å': 'stop', '–≤—ã—Ö–æ–¥': 'stop', 'exit': 'stop',
        '–ø–∞—É–∑–∞': 'pause', '–ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å': 'resume', '—Ç–∏—à–µ': 'volume_down',
        '–≥—Ä–æ–º—á–µ': 'volume_up', '–≤—ã–∫–ª—é—á–∏ –∑–≤—É–∫': 'mute', '–≤–∫–ª—é—á–∏ –∑–≤—É–∫': 'unmute',
        '–ø–æ–º–æ—â—å': 'help', '–∫–æ–º–∞–Ω–¥—ã': 'commands', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞': 'stats'
    }
    
    def __init__(self, 
                 wake_word: str = "–∏—Ä–∏—Å",
                 sensitivity: float = 0.8,
                 recognition_mode: str = "hybrid",
                 vosk_model_path: Optional[str] = None,
                 audio_device_index: Optional[int] = None,
                 sample_rate: int = 16000,
                 enable_analytics: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞
        
        Args:
            wake_word: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
            sensitivity: –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (0.1-1.0)
            recognition_mode: –†–µ–∂–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (vosk, google, hybrid, simple)
            vosk_model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ Vosk
            audio_device_index: –ò–Ω–¥–µ–∫—Å –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            enable_analytics: –í–∫–ª—é—á–∏—Ç—å —Å–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        """
        print("=" * 60)
        print("üé§ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´ –ì–û–õ–û–°–û–í–û–ì–û –í–í–û–î–ê")
        print("=" * 60)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.wake_word = wake_word.lower()
        self.sensitivity = max(0.1, min(1.0, sensitivity))
        self.recognition_mode = recognition_mode
        self.audio_device_index = audio_device_index
        self.enable_analytics = enable_analytics
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        self._determine_recognition_mode()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ
        self.sample_rate = sample_rate
        self.audio_settings = AudioSettings(
            sample_rate=sample_rate,
            energy_threshold=int(1500 + (3500 * (1 - sensitivity)))
        )
        
        # –°–∏—Å—Ç–µ–º–∞ –æ—á–µ—Ä–µ–¥–µ–π
        self.command_queue = queue.PriorityQueue()  # (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –≤—Ä–µ–º—è, –∫–æ–º–∞–Ω–¥–∞)
        self.audio_buffer = queue.Queue()
        
        # –§–ª–∞–≥–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.is_listening = False
        self.is_calibrating = False
        self.is_active = False  # –†–µ–∂–∏–º –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø–æ—Å–ª–µ wake word
        self.activation_timeout = 8.0  # –°–µ–∫—É–Ω–¥ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ wake word
        self.last_activation_time = 0
        self.last_audio_time = 0
        
        # –ö–æ–ª–ª–±—ç–∫–∏
        self.command_callback: Optional[Callable[[str], None]] = None
        self.wake_callback: Optional[Callable[[], None]] = None
        self.error_callback: Optional[Callable[[Exception], None]] = None
        
        # –ò—Å—Ç–æ—Ä–∏—è –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.recognition_history: List[Dict[str, Any]] = []
        self.max_history = 100
        self.stats = RecognitionStats()
        
        # –ú–æ–¥–µ–ª–∏ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª–∏
        self.vosk_model = None
        self.vosk_recognizer = None
        self.sr_recognizer = None
        self.audio_stream = None
        self.pyaudio_instance = None
        
        # –ü–æ—Ç–æ–∫–∏
        self.listener_thread: Optional[threading.Thread] = None
        self.processor_thread: Optional[threading.Thread] = None
        self.analytics_thread: Optional[threading.Thread] = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._initialize_components(vosk_model_path)
        
        # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ
        self._print_system_info()
        
        print("[VOICE] ‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        print("=" * 60)
    
    def _determine_recognition_mode(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        if self.recognition_mode == "auto":
            if VOSK_AVAILABLE and self._check_vosk_model():
                self.recognition_mode = "vosk"
                print("[VOICE] –ê–≤—Ç–æ–≤—ã–±–æ—Ä: Vosk (–æ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º)")
            elif SR_AVAILABLE:
                self.recognition_mode = "google"
                print("[VOICE] –ê–≤—Ç–æ–≤—ã–±–æ—Ä: Google Speech (–æ–Ω–ª–∞–π–Ω —Ä–µ–∂–∏–º)")
            else:
                self.recognition_mode = "simple"
                print("[VOICE] –ê–≤—Ç–æ–≤—ã–±–æ—Ä: –ü—Ä–æ—Å—Ç–æ–π –≤–≤–æ–¥ (–∫–æ–Ω—Å–æ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º)")
    
    def _check_vosk_model(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏ Vosk"""
        model_paths = [
            "models/vosk-model-small-ru",
            "vosk-model-small-ru-0.22",
            os.path.expanduser("~/.vosk/vosk-model-small-ru"),
            "/usr/share/vosk/vosk-model-small-ru",
        ]
        return any(os.path.exists(path) for path in model_paths)
    
    def _initialize_components(self, vosk_model_path: Optional[str] = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        print("[VOICE] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Vosk
        if VOSK_AVAILABLE and self.recognition_mode in ["vosk", "hybrid"]:
            self._init_vosk_model(vosk_model_path)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SpeechRecognition
        if SR_AVAILABLE and self.recognition_mode in ["google", "hybrid"]:
            self._init_speech_recognition()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        self._init_audio_device()
        
        print("[VOICE] ‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    
    def _init_vosk_model(self, model_path: Optional[str] = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Vosk"""
        if not VOSK_AVAILABLE:
            print("[VOICE] ‚ö†Ô∏è Vosk –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")
            return
        
        # –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏ Vosk
        model_paths = [
            model_path,
            "models/vosk-model-ru-0.22",
            "vosk-model-ru-0.22",
            os.path.expanduser("~/.vosk/vosk-model-ru-0.22"),
            "/usr/share/vosk/vosk-model-ru-0.22",
        ]
        
        for path in model_paths:
            if path and os.path.exists(path):
                try:
                    print(f"[VOICE] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Vosk: {path}")
                    self.vosk_model = Model(path)
                    self.vosk_recognizer = KaldiRecognizer(self.vosk_model, self.sample_rate)
                    self.vosk_recognizer.SetWords(True)
                    print(f"[VOICE] ‚úÖ –ú–æ–¥–µ–ª—å Vosk –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {path}")
                    return
                except Exception as e:
                    print(f"[VOICE] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {path}: {e}")
        
        print("[VOICE] ‚ö†Ô∏è –ú–æ–¥–µ–ª—å Vosk –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –æ–Ω–ª–∞–π–Ω —Ä–µ–∂–∏–º –±—É–¥–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–º")
        if self.recognition_mode == "vosk":
            self.recognition_mode = "google"
    
    def _init_speech_recognition(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SpeechRecognition"""
        if not SR_AVAILABLE:
            print("[VOICE] ‚ö†Ô∏è SpeechRecognition –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        try:
            self.sr_recognizer = sr.Recognizer()
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–µ—á–∏
            self.sr_recognizer.pause_threshold = 0.5
            self.sr_recognizer.phrase_threshold = 0.3
            self.sr_recognizer.non_speaking_duration = 0.3
            self.sr_recognizer.energy_threshold = self.audio_settings.energy_threshold
            self.sr_recognizer.dynamic_energy_threshold = True
            
            print("[VOICE] ‚úÖ SpeechRecognition –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            print(f"[VOICE] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ SpeechRecognition: {e}")
    
    def _init_audio_device(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
        print("[VOICE] –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤...")
        
        try:
            if PYAUDIO_AVAILABLE:
                self.pyaudio_instance = pyaudio.PyAudio()
                device_count = self.pyaudio_instance.get_device_count()
                print(f"[VOICE] –ù–∞–π–¥–µ–Ω–æ –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤: {device_count}")
                
                for i in range(device_count):
                    device_info = self.pyaudio_instance.get_device_info_by_index(i)
                    if device_info.get('maxInputChannels', 0) > 0:
                        print(f"  [{i}] {device_info.get('name')}")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                self.audio_device_index = self.audio_device_index or self.pyaudio_instance.get_default_input_device_info().get('index')
                print(f"[VOICE] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.audio_device_index}")
            
            elif SOUNDDEVICE_AVAILABLE:
                devices = sd.query_devices()
                print(f"[VOICE] –ù–∞–π–¥–µ–Ω–æ SoundDevice —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {len(devices)}")
                
            else:
                print("[VOICE] ‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞—É–¥–∏–æ –±–∏–±–ª–∏–æ—Ç–µ–∫, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤–≤–æ–¥")
                self.recognition_mode = "simple"
                
        except Exception as e:
            print(f"[VOICE] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
            self.recognition_mode = "simple"
    
    def _print_system_info(self):
        """–í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ"""
        print("\n[VOICE] üìä –°–ò–°–¢–ï–ú–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø")
        print(f"   ‚Ä¢ Wake word: '{self.wake_word}'")
        print(f"   ‚Ä¢ –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {self.sensitivity:.1f}")
        print(f"   ‚Ä¢ –†–µ–∂–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {self.recognition_mode}")
        print(f"   ‚Ä¢ –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {self.sample_rate} Hz")
        print(f"   ‚Ä¢ Vosk –¥–æ—Å—Ç—É–ø–µ–Ω: {'‚úÖ' if VOSK_AVAILABLE else '‚ùå'}")
        print(f"   ‚Ä¢ Google Speech –¥–æ—Å—Ç—É–ø–µ–Ω: {'‚úÖ' if SR_AVAILABLE else '‚ùå'}")
        print(f"   ‚Ä¢ PyAudio –¥–æ—Å—Ç—É–ø–µ–Ω: {'‚úÖ' if PYAUDIO_AVAILABLE else '‚ùå'}")
        print(f"   ‚Ä¢ SoundDevice –¥–æ—Å—Ç—É–ø–µ–Ω: {'‚úÖ' if SOUNDDEVICE_AVAILABLE else '‚ùå'}")
        print(f"   ‚Ä¢ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞: {'‚úÖ' if self.enable_analytics else '‚ùå'}")
    
    def _check_wake_word(self, text: str, confidence: float = 1.0) -> Tuple[bool, str]:
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ wake word —Å fuzzy matching –∏ confidence scoring
        
        Args:
            text: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            confidence: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (0.0-1.0)
            
        Returns:
            Tuple[bool, str]: (–Ω–∞–π–¥–µ–Ω –ª–∏ wake word, –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)
        """
        if not text or len(text.strip()) < 2:
            return False, ""
        
        text_lower = text.lower().strip()
        words = text_lower.split()
        
        # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ª—é–±—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º
        for variant in self.WAKE_WORD_VARIANTS:
            if variant in text_lower:
                print(f"[VOICE] üîç Wake word –Ω–∞–π–¥–µ–Ω (—Ç–æ—á–Ω–æ–µ): '{variant}'")
                return True, text_lower.replace(variant, "", 1).strip()
        
        # 2. –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ 3 —Å–∏–º–≤–æ–ª–∞)
        for word in words:
            if len(word) >= 3:
                for variant in self.WAKE_WORD_VARIANTS:
                    if (word.startswith(variant[:3]) or 
                        variant.startswith(word[:3])):
                        print(f"[VOICE] üîç Wake word –Ω–∞–π–¥–µ–Ω (—á–∞—Å—Ç–∏—á–Ω–æ–µ): '{word}' ~ '{variant}'")
                        return True, text_lower.replace(word, "", 1).strip()
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—Å—Ç–∞
        for variant in self.WAKE_WORD_VARIANTS:
            if text_lower.startswith(variant):
                print(f"[VOICE] üîç Wake word –Ω–∞–π–¥–µ–Ω (–Ω–∞—á–∞–ª–æ): '{variant}'")
                return True, text_lower[len(variant):].strip()
        
        # 4. Fuzzy matching –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        wake_chars = set(self.wake_word)
        for word in words:
            if len(word) >= 3:
                word_chars = set(word)
                overlap = len(wake_chars & word_chars)
                if overlap >= len(wake_chars) * 0.7:  # 70% —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤
                    print(f"[VOICE] üîç Wake word –Ω–∞–π–¥–µ–Ω (fuzzy): '{word}'")
                    return True, text_lower.replace(word, "", 1).strip()
        
        # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±—ã—Å—Ç—Ä–æ–π —Ä–µ—á–∏ (—Å–ª–∏—Ç–Ω—ã–µ —Å–ª–æ–≤–∞)
        for variant in self.WAKE_WORD_VARIANTS:
            if len(variant) >= 3 and text_lower[:3] == variant[:3]:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –≥–¥–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è wake word
                for i in range(3, min(len(text_lower), len(variant) + 2)):
                    if text_lower[:i] == variant[:i]:
                        print(f"[VOICE] üîç Wake word –Ω–∞–π–¥–µ–Ω (–±—ã—Å—Ç—Ä–∞—è —Ä–µ—á—å): '{variant[:i]}'")
                        return True, text_lower[i:].strip()
        
        return False, text_lower
    
    def _extract_command(self, text: str) -> str:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –±—ã—Å—Ç—Ä–æ–π —Ä–µ—á–∏
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            str: –ò–∑–≤–ª–µ—á–µ–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞
        """
        if not text:
            return ""
        
        text_lower = text.lower().strip()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±—ã—Å—Ç—Ä—ã—Ö –∫–æ–º–∞–Ω–¥
        for cmd_key, cmd_value in self.QUICK_COMMANDS.items():
            if cmd_key in text_lower:
                return cmd_value
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –∫–æ–º–∞–Ω–¥—É –ø–æ—Å–ª–µ wake word
        is_wake, cleaned_text = self._check_wake_word(text_lower)
        if is_wake:
            return cleaned_text
        
        # –ï—Å–ª–∏ wake word –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–æ —Ç–µ–∫—Å—Ç –ø–æ—Ö–æ–∂ –Ω–∞ –∫–æ–º–∞–Ω–¥—É
        if len(text_lower.split()) <= 5:  # –ö–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã
            return text_lower
        
        return ""
    
    def _recognize_with_vosk(self, audio_data: bytes) -> Optional[Dict[str, Any]]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Vosk"""
        if not self.vosk_recognizer:
            return None
        
        try:
            if self.vosk_recognizer.AcceptWaveform(audio_data):
                result = json.loads(self.vosk_recognizer.Result())
                text = result.get('text', '').strip()
                if text:
                    return {
                        'text': text,
                        'confidence': 0.9,
                        'source': 'vosk',
                        'timestamp': time.time()
                    }
            else:
                partial = json.loads(self.vosk_recognizer.PartialResult())
                text = partial.get('partial', '').strip()
                if text and len(text) > 3:
                    return {
                        'text': text,
                        'confidence': 0.6,
                        'source': 'vosk_partial',
                        'timestamp': time.time()
                    }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ Vosk —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
        
        return None
    
    def _recognize_with_google(self, audio_data) -> Optional[Dict[str, Any]]:
        """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Google Speech API"""
        if not self.sr_recognizer:
            return None
        
        try:
            text = self.sr_recognizer.recognize_google(audio_data, language="ru-RU")
            return {
                'text': text,
                'confidence': 0.85,
                'source': 'google',
                'timestamp': time.time()
            }
        except sr.UnknownValueError:
            return None
        except sr.RequestError as e:
            logger.error(f"–û—à–∏–±–∫–∞ Google Speech API: {e}")
            return None
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ Google —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return None
    
    def _process_audio_chunk(self, audio_data: bytes):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—á–∞–Ω–∫–∞ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏"""
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∞—É–¥–∏–æ
        self.last_audio_time = time.time()
        
        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        results = []
        
        if self.recognition_mode in ["vosk", "hybrid"] and self.vosk_recognizer:
            vosk_result = self._recognize_with_vosk(audio_data)
            if vosk_result:
                results.append(vosk_result)
        
        # –î–ª—è Google –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∞—É–¥–∏–æ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        if self.recognition_mode in ["google", "hybrid"] and self.sr_recognizer:
            try:
                # –°–æ–∑–¥–∞–µ–º AudioData –¥–ª—è SpeechRecognition
                import wave
                import io
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º bytes –≤ AudioData
                audio_data_sr = sr.AudioData(
                    audio_data, 
                    self.sample_rate, 
                    2  # sample width in bytes
                )
                
                google_result = self._recognize_with_google(audio_data_sr)
                if google_result:
                    results.append(google_result)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∞—É–¥–∏–æ –¥–ª—è Google: {e}")
        
        # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if results:
            # –í—ã–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            best_result = max(results, key=lambda x: x.get('confidence', 0))
            self._process_recognition_result(best_result)
    
    def _process_recognition_result(self, result: Dict[str, Any]):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        if not result or 'text' not in result:
            return
        
        text = result['text']
        confidence = result.get('confidence', 0.5)
        source = result.get('source', 'unknown')
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats.total_phrases += 1
        if source == 'vosk':
            self.stats.vosk_success += 1
        elif source == 'google':
            self.stats.google_success += 1
        
        self.stats.avg_confidence = (
            (self.stats.avg_confidence * (self.stats.total_phrases - 1) + confidence) 
            / self.stats.total_phrases
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        history_entry = {
            'text': text,
            'confidence': confidence,
            'source': source,
            'timestamp': time.time(),
            'mode': self.recognition_mode,
            'sensitivity': self.sensitivity
        }
        
        self.recognition_history.append(history_entry)
        if len(self.recognition_history) > self.max_history:
            self.recognition_history.pop(0)
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏
        source_icon = "üé§" if source == 'vosk' else "üåê"
        print(f"{source_icon} [VOICE] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{text}' (–¥–æ–≤–µ—Ä–∏–µ: {confidence:.1%})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º wake word
        is_wake, cleaned_text = self._check_wake_word(text, confidence)
        
        if is_wake:
            self.stats.wake_detected += 1
            print(f"üîî [VOICE] Wake word –æ–±–Ω–∞—Ä—É–∂–µ–Ω! –ê–∫—Ç–∏–≤–∞—Ü–∏—è –Ω–∞ {self.activation_timeout}—Å")
            
            # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º —Ä–µ–∂–∏–º –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
            self.is_active = True
            self.last_activation_time = time.time()
            
            # –í—ã–∑—ã–≤–∞–µ–º –∫–æ–ª–ª–±—ç–∫ wake word
            if self.wake_callback:
                try:
                    self.wake_callback()
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –≤ wake –∫–æ–ª–ª–±—ç–∫–µ: {e}")
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–º–∞–Ω–¥–∞ –ø–æ—Å–ª–µ wake word
            if cleaned_text:
                self._handle_command(cleaned_text, confidence)
        
        # –ï—Å–ª–∏ —É–∂–µ –≤ –∞–∫—Ç–∏–≤–Ω–æ–º —Ä–µ–∂–∏–º–µ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –∫–æ–º–∞–Ω–¥—É
        elif self.is_active:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∞–π–º–∞—É—Ç –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
            if time.time() - self.last_activation_time > self.activation_timeout:
                print(f"[VOICE] –¢–∞–π–º–∞—É—Ç –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ({self.activation_timeout}—Å)")
                self.is_active = False
            else:
                self._handle_command(text, confidence)
    
    def _handle_command(self, command: str, confidence: float):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã"""
        if not command or len(command.strip()) < 2:
            return
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å—Ç—É—é –∫–æ–º–∞–Ω–¥—É
        clean_command = self._extract_command(command)
        if not clean_command:
            return
        
        print(f"üí¨ [VOICE] –ö–æ–º–∞–Ω–¥–∞: '{clean_command}' (–¥–æ–≤–µ—Ä–∏–µ: {confidence:.1%})")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
        priority = 0 if clean_command in self.QUICK_COMMANDS.values() else 1
        self.command_queue.put((priority, time.time(), clean_command))
        
        # –í—ã–∑—ã–≤–∞–µ–º –∫–æ–ª–ª–±—ç–∫ –∫–æ–º–∞–Ω–¥—ã
        if self.command_callback:
            try:
                self.command_callback(clean_command)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ command –∫–æ–ª–ª–±—ç–∫–µ: {e}")
                if self.error_callback:
                    self.error_callback(e)
    
    def _listen_loop_vosk(self):
        """–¶–∏–∫–ª –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è —Å Vosk —á–µ—Ä–µ–∑ PyAudio"""
        print(f"[VOICE] –ó–∞–ø—É—Å–∫ Vosk –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è... (—Å–∫–∞–∂–∏—Ç–µ '{self.wake_word}')")
        
        try:
            self.audio_stream = self.pyaudio_instance.open(
                format=pyaudio.paInt16,
                channels=self.audio_settings.channels,
                rate=self.audio_settings.sample_rate,
                input=True,
                input_device_index=self.audio_device_index,
                frames_per_buffer=self.audio_settings.chunk_size,
                stream_callback=self._audio_callback_pyaudio
            )
            
            self.audio_stream.start_stream()
            
            while self.is_listening and self.audio_stream.is_active():
                time.sleep(0.1)
                
        except Exception as e:
            print(f"[VOICE] –û—à–∏–±–∫–∞ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞ Vosk: {e}")
            self._fallback_to_google()
        finally:
            if self.audio_stream:
                self.audio_stream.stop_stream()
                self.audio_stream.close()
    
    def _audio_callback_pyaudio(self, in_data, frame_count, time_info, status):
        """–ö–æ–ª–ª–±—ç–∫ –¥–ª—è PyAudio"""
        if status:
            logger.warning(f"–ê—É–¥–∏–æ —Å—Ç–∞—Ç—É—Å: {status}")
        
        self.audio_buffer.put(in_data)
        return (in_data, pyaudio.paContinue)
    
    def _audio_processor_loop(self):
        """–¶–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ–±—É—Ñ–µ—Ä–∞"""
        print("[VOICE] –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∞—É–¥–∏–æ...")
        
        while self.is_listening:
            try:
                audio_data = self.audio_buffer.get(timeout=0.5)
                self._process_audio_chunk(audio_data)
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
    
    def _listen_loop_google(self):
        """–¶–∏–∫–ª –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è —Å Google Speech —á–µ—Ä–µ–∑ SpeechRecognition"""
        print(f"[VOICE] –ó–∞–ø—É—Å–∫ Google –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è... (—Å–∫–∞–∂–∏—Ç–µ '{self.wake_word}')")
        
        try:
            with sr.Microphone(
                device_index=self.audio_device_index,
                sample_rate=self.audio_settings.sample_rate
            ) as source:
                # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞
                print("[VOICE] –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...")
                self.sr_recognizer.adjust_for_ambient_noise(source, duration=1)
                print(f"[VOICE] –ü–æ—Ä–æ–≥ —ç–Ω–µ—Ä–≥–∏–∏: {self.sr_recognizer.energy_threshold}")
                
                while self.is_listening:
                    try:
                        # –°–ª—É—à–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω
                        audio = self.sr_recognizer.listen(
                            source,
                            timeout=2,
                            phrase_time_limit=5
                        )
                        
                        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Å Google
                        result = self._recognize_with_google(audio)
                        if result:
                            self._process_recognition_result(result)
                            
                    except sr.WaitTimeoutError:
                        continue
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è Google: {e}")
                        
        except OSError as e:
            print(f"[VOICE] –ù–µ—Ç –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤: {e}")
            print("[VOICE] –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º –≤–≤–æ–¥–∞...")
            self._fallback_to_simple()
        except Exception as e:
            print(f"[VOICE] –û—à–∏–±–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: {e}")
            self._fallback_to_simple()
    
    def _listen_loop_simple(self):
        """–¶–∏–∫–ª –ø—Ä–æ—Å—Ç–æ–≥–æ –∫–æ–Ω—Å–æ–ª—å–Ω–æ–≥–æ –≤–≤–æ–¥–∞"""
        print(f"[VOICE] –ü—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º. –í–≤–µ–¥–∏—Ç–µ –∫–æ–º–∞–Ω–¥—ã –≤—Ä—É—á–Ω—É—é.")
        print(f"[VOICE] –î–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤–≤–µ–¥–∏—Ç–µ: '{self.wake_word}'")
        
        while self.is_listening:
            try:
                user_input = input("[–ì–æ–ª–æ—Å] > ").strip()
                
                if not user_input:
                    continue
                
                # –°–æ–∑–¥–∞–µ–º –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
                result = {
                    'text': user_input,
                    'confidence': 1.0,
                    'source': 'console',
                    'timestamp': time.time()
                }
                
                self._process_recognition_result(result)
                
            except (EOFError, KeyboardInterrupt):
                break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤–≤–æ–¥–∞: {e}")
    
    def _fallback_to_google(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ Google Speech –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤"""
        print("[VOICE] –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ Google Speech...")
        self.recognition_mode = "google"
        self.stop()
        time.sleep(1)
        self.start()
    
    def _fallback_to_simple(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º"""
        print("[VOICE] –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º –≤–≤–æ–¥–∞...")
        self.recognition_mode = "simple"
        self.stop()
        time.sleep(1)
        self.start()
    
    def _analytics_loop(self):
        """–¶–∏–∫–ª —Å–±–æ—Ä–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
        if not self.enable_analytics:
            return
        
        print("[VOICE] –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∏...")
        
        while self.is_listening:
            try:
                time.sleep(30)  # –ö–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                
                # –†–∞—Å—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ
                if self.last_audio_time > 0:
                    time_since_audio = time.time() - self.last_audio_time
                    audio_quality = 1.0 - min(time_since_audio / 60, 1.0)  # –£—Ö—É–¥—à–µ–Ω–∏–µ —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º
                    self.stats.audio_quality = audio_quality
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                if self.stats.total_phrases > 0:
                    logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {self.stats.total_phrases} —Ñ—Ä–∞–∑, "
                               f"{self.stats.wake_detected} wake, "
                               f"—Ç–æ—á–Ω–æ—Å—Ç—å: {self.stats.avg_confidence:.1%}")
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
    
    def start(self):
        """–ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞"""
        if self.is_listening:
            print("[VOICE] –°–∏—Å—Ç–µ–º–∞ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–∞")
            return
        
        print("[VOICE] üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞...")
        self.is_listening = True
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        if self.recognition_mode == "vosk" and VOSK_AVAILABLE and PYAUDIO_AVAILABLE:
            self.listener_thread = threading.Thread(target=self._listen_loop_vosk, daemon=True)
            self.processor_thread = threading.Thread(target=self._audio_processor_loop, daemon=True)
            self.processor_thread.start()
            
        elif self.recognition_mode == "google" and SR_AVAILABLE:
            self.listener_thread = threading.Thread(target=self._listen_loop_google, daemon=True)
            
        elif self.recognition_mode == "hybrid":
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–∞ —Ä–µ–∂–∏–º–∞
            self.listener_thread = threading.Thread(target=self._listen_loop_vosk, daemon=True)
            self.processor_thread = threading.Thread(target=self._audio_processor_loop, daemon=True)
            self.processor_thread.start()
            
        else:  # simple mode
            self.listener_thread = threading.Thread(target=self._listen_loop_simple, daemon=True)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
        if self.listener_thread:
            self.listener_thread.start()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É
        if self.enable_analytics:
            self.analytics_thread = threading.Thread(target=self._analytics_loop, daemon=True)
            self.analytics_thread.start()
        
        print(f"[VOICE] ‚úÖ –°–∏—Å—Ç–µ–º–∞ –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º–µ: {self.recognition_mode}")
        print(f"[VOICE] Wake word: '{self.wake_word}', —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {self.sensitivity}")
    
    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞"""
        if not self.is_listening:
            return
        
        print("[VOICE] –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞...")
        self.is_listening = False
        self.is_active = False
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫
        if self.audio_stream and self.audio_stream.is_active():
            self.audio_stream.stop_stream()
            self.audio_stream.close()
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º PyAudio
        if self.pyaudio_instance:
            self.pyaudio_instance.terminate()
        
        # –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤
        threads = [self.listener_thread, self.processor_thread, self.analytics_thread]
        for thread in threads:
            if thread and thread.is_alive():
                thread.join(timeout=2.0)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if self.enable_analytics:
            self._save_stats()
        
        print("[VOICE] ‚úÖ –°–∏—Å—Ç–µ–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
    
    def calibrate_microphone(self):
        """–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –¥–ª—è —Ç–µ–∫—É—â–∏—Ö —É—Å–ª–æ–≤–∏–π"""
        if self.is_calibrating:
            return
        
        self.is_calibrating = True
        print("[VOICE] –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞...")
        
        try:
            if self.sr_recognizer:
                with sr.Microphone() as source:
                    # –ë—ã—Å—Ç—Ä–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞
                    self.sr_recognizer.adjust_for_ambient_noise(source, duration=0.5)
                    
                    # –¢–µ—Å—Ç–æ–≤–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
                    print("[VOICE] –°–∫–∞–∂–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤—É—é —Ñ—Ä–∞–∑—É...")
                    audio = self.sr_recognizer.listen(source, timeout=3)
                    
                    try:
                        text = self.sr_recognizer.recognize_google(audio, language="ru-RU")
                        print(f"[VOICE] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{text}'")
                        
                        # –ê–≤—Ç–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–µ—Ä–≥–∏–∏ –∑–≤—É–∫–∞
                        if hasattr(audio, 'frame_data'):
                            import numpy as np
                            audio_data = np.frombuffer(audio.frame_data, dtype=np.int16)
                            energy = np.sqrt(np.mean(audio_data.astype(np.float32) ** 2))
                            
                            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ä–æ–≥ –Ω–∞ 60% –æ—Ç —ç–Ω–µ—Ä–≥–∏–∏ —Ç–µ—Å—Ç–æ–≤–æ–π —Ñ—Ä–∞–∑—ã
                            new_threshold = int(energy * 0.6)
                            if 1000 < new_threshold < 10000:
                                self.sr_recognizer.energy_threshold = new_threshold
                                self.audio_settings.energy_threshold = new_threshold
                                print(f"[VOICE] –ê–≤—Ç–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–∞: {new_threshold}")
                                
                    except sr.UnknownValueError:
                        print("[VOICE] –†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
                        
        except Exception as e:
            print(f"[VOICE] –û—à–∏–±–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {e}")
        finally:
            self.is_calibrating = False
            print("[VOICE] –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    def set_command_callback(self, callback: Callable[[str], None]):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥"""
        self.command_callback = callback
        print("[VOICE] Callback –∫–æ–º–∞–Ω–¥ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    def set_wake_callback(self, callback: Callable[[], None]):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ wake word"""
        self.wake_callback = callback
        print("[VOICE] Callback wake word —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    def set_error_callback(self, callback: Callable[[Exception], None]):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        self.error_callback = callback
        print("[VOICE] Callback –æ—à–∏–±–æ–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    def set_sensitivity(self, sensitivity: float):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (0.0-1.0)"""
        self.sensitivity = max(0.1, min(1.0, sensitivity))
        self.audio_settings.energy_threshold = int(1500 + (3500 * (1 - self.sensitivity)))
        
        if self.sr_recognizer:
            self.sr_recognizer.energy_threshold = self.audio_settings.energy_threshold
        
        print(f"[VOICE] –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∞: {self.sensitivity}, "
              f"–ø–æ—Ä–æ–≥: {self.audio_settings.energy_threshold}")
    
    def set_activation_timeout(self, timeout: float):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        self.activation_timeout = max(1.0, timeout)
        print(f"[VOICE] –¢–∞–π–º–∞—É—Ç –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {timeout}—Å")
    
    def get_command(self) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–∞–Ω–¥—ã –∏–∑ –æ—á–µ—Ä–µ–¥–∏"""
        try:
            priority, timestamp, command = self.command_queue.get_nowait()
            return command
        except queue.Empty:
            return None
    
    def get_recognition_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        stats_dict = asdict(self.stats)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        stats_dict.update({
            'mode': self.recognition_mode,
            'sensitivity': self.sensitivity,
            'is_active': self.is_active,
            'is_listening': self.is_listening,
            'history_size': len(self.recognition_history),
            'queue_size': self.command_queue.qsize(),
            'activation_timeout': self.activation_timeout,
            'time_since_activation': time.time() - self.last_activation_time if self.last_activation_time > 0 else -1,
            'audio_available': PYAUDIO_AVAILABLE or SOUNDDEVICE_AVAILABLE,
        })
        
        return stats_dict
    
    def get_recent_history(self, count: int = 10) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø–∏—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏"""
        return self.recognition_history[-count:] if self.recognition_history else []
    
    def clear_history(self):
        """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        self.recognition_history.clear()
        print("[VOICE] –ò—Å—Ç–æ—Ä–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –æ—á–∏—â–µ–Ω–∞")
    
    def _save_stats(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ —Ñ–∞–π–ª"""
        if not self.enable_analytics:
            return
        
        try:
            stats_file = "voice_stats.json"
            stats_data = {
                'timestamp': time.time(),
                'stats': asdict(self.stats),
                'settings': {
                    'wake_word': self.wake_word,
                    'sensitivity': self.sensitivity,
                    'mode': self.recognition_mode,
                    'sample_rate': self.sample_rate,
                },
                'recent_history': self.get_recent_history(20)
            }
            
            import json
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, indent=2, ensure_ascii=False)
                
            print(f"[VOICE] –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {stats_file}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    def stop_listening(self):
        """–ê–ª–∏–∞—Å –¥–ª—è stop (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
        self.stop()
    
    def manual_activate(self, duration: float = 10.0):
        """–†—É—á–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è —Ä–µ–∂–∏–º–∞ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è"""
        self.is_active = True
        self.last_activation_time = time.time()
        self.activation_timeout = duration
        print(f"[VOICE] –†—É—á–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è –Ω–∞ {duration} —Å–µ–∫—É–Ω–¥")


# –ü—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–±–µ–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞)
class SimpleVoiceInput:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤–≤–æ–¥ –≤–º–µ—Å—Ç–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    """
    
    def __init__(self, wake_word: str = "–∏—Ä–∏—Å", sensitivity: float = 0.8):
        print("[SimpleVoice] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞...")
        self.wake_word = wake_word
        self.sensitivity = sensitivity
        self.command_callback = None
        self.wake_callback = None
        self.is_running = False
        self.input_thread = None
    
    def set_command_callback(self, callback):
        self.command_callback = callback
    
    def set_wake_callback(self, callback):
        self.wake_callback = callback
    
    def _input_loop(self):
        print(f"[SimpleVoice] –í–≤–µ–¥–∏—Ç–µ –∫–æ–º–∞–Ω–¥—ã. –î–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: '{self.wake_word}'")
        
        while self.is_running:
            try:
                user_input = input("[–ì–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥] > ").strip().lower()
                
                if not user_input:
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ wake word
                if self.wake_word in user_input:
                    print(f"[SimpleVoice] Wake word –æ–±–Ω–∞—Ä—É–∂–µ–Ω: '{self.wake_word}'")
                    if self.wake_callback:
                        self.wake_callback()
                
                # –ü–µ—Ä–µ–¥–∞—á–∞ –∫–æ–º–∞–Ω–¥—ã
                if self.command_callback:
                    self.command_callback(user_input)
                    
            except (EOFError, KeyboardInterrupt):
                break
            except Exception as e:
                print(f"[SimpleVoice] –û—à–∏–±–∫–∞ –≤–≤–æ–¥–∞: {e}")
    
    def start(self):
        self.is_running = True
        self.input_thread = threading.Thread(target=self._input_loop, daemon=True)
        self.input_thread.start()
        print("[SimpleVoice] –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥ –∑–∞–ø—É—â–µ–Ω")
    
    def stop(self):
        self.is_running = False
        if self.input_thread and self.input_thread.is_alive():
            self.input_thread.join(timeout=1.0)
        print("[SimpleVoice] –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


# –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞
def create_voice_input(wake_word: str = "–∏—Ä–∏—Å", 
                       sensitivity: float = 0.8,
                       mode: str = "auto",
                       **kwargs) -> VoiceInput:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞
    
    Args:
        wake_word: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        sensitivity: –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (0.1-1.0)
        mode: –†–µ–∂–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (auto, vosk, google, hybrid, simple)
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        
    Returns:
        VoiceInput –∏–ª–∏ SimpleVoiceInput
    """
    print(f"–°–æ–∑–¥–∞–Ω–∏–µ VoiceInput: wake_word='{wake_word}', mode={mode}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    has_audio = PYAUDIO_AVAILABLE or SOUNDDEVICE_AVAILABLE
    has_vosk = VOSK_AVAILABLE
    has_google = SR_AVAILABLE
    
    # –ï—Å–ª–∏ —Ä–µ–∂–∏–º auto, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π
    if mode == "auto":
        if has_vosk and has_audio:
            mode = "vosk"
        elif has_google and has_audio:
            mode = "google"
        else:
            mode = "simple"
    
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω —Å–ª–æ–∂–Ω—ã–π —Ä–µ–∂–∏–º, –Ω–æ –Ω–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ - —É–ø—Ä–æ—â–∞–µ–º
    if mode in ["vosk", "hybrid"] and not has_vosk:
        print("‚ö†Ô∏è Vosk –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ Google –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º")
        mode = "google" if has_google else "simple"
    
    if mode == "google" and not has_google:
        print("‚ö†Ô∏è Google Speech –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º")
        mode = "simple"
    
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω –ª—é–±–æ–π –∞—É–¥–∏–æ —Ä–µ–∂–∏–º, –Ω–æ –Ω–µ—Ç –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤
    if mode in ["vosk", "google", "hybrid"] and not has_audio:
        print("‚ö†Ô∏è –ê—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º")
        mode = "simple"
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä
    if mode == "simple":
        return SimpleVoiceInput(wake_word, sensitivity)
    else:
        return VoiceInput(
            wake_word=wake_word,
            sensitivity=sensitivity,
            recognition_mode=mode,
            **kwargs
        )


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è
if __name__ == "__main__":
    print("=" * 60)
    print("üîä –¢–ï–°–¢ –ú–û–î–£–õ–Ø –ì–û–õ–û–°–û–í–û–ì–û –í–í–û–î–ê")
    print("=" * 60)
    
    def test_wake():
        print("\nüéØ –¢–ï–°–¢: Wake word –æ–±–Ω–∞—Ä—É–∂–µ–Ω!")
    
    def test_command(command: str):
        print(f"\nüí¨ –¢–ï–°–¢: –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞: '{command}'")
    
    def test_error(error: Exception):
        print(f"\n‚ö†Ô∏è –¢–ï–°–¢: –û—à–∏–±–∫–∞: {error}")
    
    try:
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä
        voice = create_voice_input(
            wake_word="–∏—Ä–∏—Å",
            sensitivity=0.8,
            mode="auto",
            enable_analytics=True
        )
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–ª–ª–±—ç–∫–∏
        voice.set_wake_callback(test_wake)
        voice.set_command_callback(test_command)
        voice.set_error_callback(test_error)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º
        print("\n‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã...")
        voice.start()
        
        print("\nüìù –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:")
        print("   ‚Ä¢ –°–∫–∞–∂–∏—Ç–µ '–ò—Ä–∏—Å' –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏")
        print("   ‚Ä¢ –ó–∞—Ç–µ–º –ø—Ä–æ–∏–∑–Ω–µ—Å–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É")
        print("   ‚Ä¢ –ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –≤—Ä—É—á–Ω—É—é (–≤ –ø—Ä–æ—Å—Ç–æ–º —Ä–µ–∂–∏–º–µ)")
        print("   ‚Ä¢ –°–∫–∞–∂–∏—Ç–µ '—Å—Ç–æ–ø' –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç–µ—Å—Ç–∞")
        print("\n‚è≥ –¢–µ—Å—Ç –Ω–∞ 30 —Å–µ–∫—É–Ω–¥...")
        
        # –ñ–¥–µ–º 30 —Å–µ–∫—É–Ω–¥ –∏–ª–∏ –∫–æ–º–∞–Ω–¥—É —Å—Ç–æ–ø
        import time
        start_time = time.time()
        
        while time.time() - start_time < 30:
            time.sleep(1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–∞–Ω–¥—É —Å—Ç–æ–ø
            cmd = voice.get_command()
            if cmd == "stop":
                print("\nüõë –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ —Å—Ç–æ–ø")
                break
            
            # –†–∞–∑ –≤ 5 —Å–µ–∫—É–Ω–¥ –≤—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            if int(time.time() - start_time) % 5 == 0:
                stats = voice.get_recognition_stats()
                print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats['total_phrases']} —Ñ—Ä–∞–∑, "
                      f"{stats['wake_detected']} wake, "
                      f"–æ—á–µ—Ä–µ–¥—å: {stats['queue_size']}")
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
        print("\n‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã...")
        voice.stop()
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "=" * 60)
        print("üìà –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("=" * 60)
        
        stats = voice.get_recognition_stats()
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        print("\n" + "=" * 60)
        print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print("=" * 60)
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")
        import traceback
        traceback.print_exc()